{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO0eelv26utHwB6WvlSzqex",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GabrielKlose18/ia-trabalho-01/blob/main/Notebooks_questoes/IA_Trabalho_01_Quest%C3%B5es_4%2C5%2C6_e_7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Questão 04\n",
        "\n",
        "### ***O Dilema Bias-Variance Tradeoff***\n",
        "\n",
        "O tradeoff entre bias e variância está no fato de que, ao reduzir o bias, geralmente aumentamos a variância, e vice-versa. O objetivo é encontrar um equilíbrio, onde o modelo não seja nem muito simples (alto bias) nem excessivamente complexo (alta variância).\n",
        "\n",
        "Um modelo com alto bias apresenta underfitting, pois é incapaz de capturar as características importantes do conjunto de dados.\n",
        "Um modelo com alta variância apresenta overfitting, pois é muito adaptado ao conjunto de treino e não consegue generalizar para novos dados.\n",
        "\n",
        "### ***Underfitting e Overfitting***\n",
        "\n",
        "Underfitting:\n",
        "\n",
        "Ocorre quando o modelo é muito simples e não captura a complexidade dos dados, resultando em baixo desempenho tanto no treino quanto no teste.\n",
        "Sintomas: erro elevado nos dados de treino e teste.\n",
        "Causado por alto bias e baixa variância.\n",
        "Overfitting:\n",
        "\n",
        "Ocorre quando o modelo é muito complexo e se ajusta demais aos dados de treino, capturando ruídos em vez de padrões genuínos.\n",
        "Sintomas: bom desempenho no treino, mas desempenho ruim no teste.\n",
        "Causado por baixa bias e alta variância.\n",
        "\n",
        "### ***Resumo da Relação entre Bias, Variância, Underfitting e Overfitting***\n",
        "\n",
        "Alto Bias → Underfitting (modelo muito simples, não captura padrões)\n",
        "Alta Variância → Overfitting (modelo muito complexo, captura ruídos)\n",
        "Tradeoff Bias-Variância: Encontrar o equilíbrio onde o modelo não é nem muito simples nem muito complexo, resultando em um bom desempenho em treino e teste."
      ],
      "metadata": {
        "id": "a4iz5NrIENV9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJPuOHWaEMVp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Questão 05\n",
        "\n",
        "### A) Falso - mais variáveis de entrada nem sempre melhoram a qualidade do modelo.\n",
        "\n",
        "###B) Verdadeiro - mais amostras tendem a ajudar, desde que sejam de qualidade.\n",
        "\n",
        "###C) Verdadeiro - manipulações simples nos dados podem melhorar os resultados significativamente.\n"
      ],
      "metadata": {
        "id": "8v_yaefZG2r3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Questão 06\n",
        "\n",
        "### A) O gerente não se sentiu empolgado porque a alta acurácia pode ser enganosa em problemas de classe desbalanceada. O modelo provavelmente está ignorando a classe minoritária e apenas acertando as predições da classe majoritária : peças boas. No entanto, por serem a maioria, o modelo consegue alta acurácia.\n",
        "\n",
        "### B) O funcionário deveria calcular métricas como precisão, recall e F1-score para melhor avaliar o desempenho do modelo na detecção de defeitos. Além disso, ajustes no limiar da decisão ou técnicas de balanceamento de classes poderiam melhorar a eficácia do modelo."
      ],
      "metadata": {
        "id": "Y1YKj4vTIDqG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Questão 07\n",
        "\n",
        "### Estratégias para Avaliar uma Amostra com Variáveis Faltantes em Árvores de Decisão Árvores de decisão são particularmente flexíveis em relação a variáveis faltantes, e há algumas abordagens práticas para lidar com esses casos:\n",
        "\n",
        "1. Seguir a Divisão Baseada na Probabilidade dos Filhos\n",
        "Quando uma amostra chega em um nó que utiliza uma variável faltante para tomar uma decisão, é possível distribuir a amostra entre os nós filhos com base na probabilidade de cada filho. Por exemplo, se a maioria das amostras anteriores seguiu para o nó esquerdo, a amostra pode ter uma probabilidade maior de seguir o mesmo caminho.\n",
        "No final, cada caminho (ou nó folha) receberá uma fração da amostra. A previsão final é então feita com base na média ponderada das previsões de cada caminho, ponderada pelas probabilidades.\n",
        "\n",
        "2. Imputação de Valores Faltantes\n",
        "Outra estratégia é imputar valores faltantes usando métodos estatísticos como a média, mediana ou moda (para variáveis contínuas ou categóricas).\n",
        "Algumas implementações de árvores de decisão, como o XGBoost, permitem especificar valores padrão para os valores ausentes e tratam-nos diretamente, o que pode facilitar a aplicação.\n",
        "Essa abordagem, embora simples, pode introduzir algum viés, mas ajuda a seguir um caminho específico sem cálculos adicionais.\n",
        "\n",
        "3. Usar o Valor Mais Comum do Conjunto de Treinamento no Nó Atual\n",
        "Ao lidar com valores faltantes em uma variável específica em um nó de decisão, é possível substituir o valor ausente pelo valor mais comum (moda) da variável na porção do conjunto de treino que alcançou aquele nó.\n",
        "Essa abordagem é particularmente útil em variáveis categóricas, onde o valor mais comum pode ser representativo da maioria das amostras naquele ponto da árvore.\n",
        "\n",
        "4. Ignorar a Divisão para Variáveis Faltantes\n",
        "Algumas implementações permitem ignorar a divisão com a variável faltante. Nesse caso, a árvore considera apenas divisões com variáveis preenchidas, o que pode ser menos preciso mas mantém o processo sem necessidade de imputação.\n",
        "Por exemplo, ao construir a árvore, podemos configurar para que as variáveis com muitos valores ausentes não sejam usadas como critérios de divisão."
      ],
      "metadata": {
        "id": "2tT4LU4AJDfm"
      }
    }
  ]
}